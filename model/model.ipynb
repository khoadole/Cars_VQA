{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import ImageEnhance, Image\n",
    "from pathlib import Path\n",
    "import io\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cars_df = load_dataset('khoadole/cars_8k_balance_dataset')\n",
    "cars_df = pd.DataFrame(original_cars_df[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove no car images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model():\n",
    "\tmodel = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True, trust_repo='check')\n",
    "\tmodel.conf = 0.1 # decrease confidence => higher car detect : min 0.1(conf)\n",
    "\treturn model\n",
    "\t\n",
    "def get_no_cars_rows(df : pd.DataFrame, no_cars_path : str, no_cars_rows : list):\n",
    "\tmodel = load_model()\n",
    "\tfor index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\t\timage_bytes = row['image']\n",
    "\n",
    "\t\timage_raw = Image.open(io.BytesIO(image_bytes[\"bytes\"]))\n",
    "\t\timage = image_raw\n",
    "\t\timage = image.resize((640, 480), Image.LANCZOS)\n",
    "\n",
    "\t\tenhancer = ImageEnhance.Brightness(image)\n",
    "\t\timage = enhancer.enhance(0.5)\n",
    "\t\tenhancer = ImageEnhance.Contrast(image)\n",
    "\t\timage = enhancer.enhance(0.5)\n",
    "\n",
    "\t\tresults = model(image)\n",
    "\n",
    "\t\tdetections = results.pandas().xyxy[0]\n",
    "\n",
    "\t\tif 'car' in detections['name'].values:\n",
    "\t\t\tprint()\n",
    "\t\telse:\n",
    "\t\t\t# Save raw no car detected images\n",
    "\t\t\t# no_cars_path.mkdir(exist_ok=True)\n",
    "\t\t\t# image_raw.save(no_cars_path / f\"{index}.jpg\")\n",
    "\n",
    "\t\t\t# results.show()\n",
    "\t\t\t# display(image)\n",
    "\n",
    "\t\t\tno_cars_rows.append(index)\n",
    "\n",
    "\treturn no_cars_rows\n",
    "\n",
    "# Save cols\n",
    "def save_file(filename: str, data : list):\n",
    "\twith open(filename, \"w\") as file:\n",
    "\t\tfile.write(\"\\n\".join(map(str, data)))\n",
    "\n",
    "# Load cols\n",
    "def load_cols(filename: str):\n",
    "\twith open(filename, \"r\") as file:\n",
    "\t\tdata = [int(line.strip()) for line in file]\n",
    "\treturn data\n",
    "\n",
    "# Load dataframe\n",
    "cars_short = cars_df\n",
    "\n",
    "## Load cols from file(if exists)\n",
    "if Path(\"../data/no_cars_rows.txt\").exists():\n",
    "\tno_cars_rows = load_cols(\"../data/no_cars_rows.txt\")\n",
    "else:\n",
    "\t# Path\n",
    "\tcwd = Path.cwd()\n",
    "\tno_cars_dir = cwd / 'no_cars_detected'\n",
    "\t\n",
    "\tno_cars_rows = []\n",
    "\tno_cars_rows = get_no_cars_rows(cars_short, no_cars_dir, no_cars_rows)\n",
    "\t\n",
    "\tsave_file(\"../data/no_cars_rows.txt\", no_cars_rows)\n",
    "\n",
    "# Drop rows\n",
    "cars_short.drop(no_cars_rows, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(cars_short, test_size=0.4, stratify=cars_short[\"name\"], random_state=14)\n",
    "validation, test = train_test_split(temp, test_size=0.5, stratify=temp[\"name\"], random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7819de4e68e46ceab44d0bb319e0aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0f4bd46fd442868d61653f062c0c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9241094fb74a54b338afa77b98e55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load questions\n",
    "with open('../local_data/question/brand_questions.txt', 'r') as f:\n",
    "    brand_questions = f.read().splitlines()\n",
    "with open('../local_data/question/color_questions.txt', 'r') as f:\n",
    "    color_questions = f.read().splitlines()\n",
    "with open('../local_data/question/type_questions.txt', 'r') as f:\n",
    "    type_questions = f.read().splitlines()\n",
    "\n",
    "###\n",
    "def pipeline_create_qa_dataset(df : pd.DataFrame):\n",
    "    qa_dataset = []\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        # key = row[\"name\"]\n",
    "\n",
    "        # Get questions list\n",
    "        brand_q = random.choice(brand_questions)\n",
    "        color_q = random.choice(color_questions)\n",
    "        type_q = random.choice(type_questions)\n",
    "\n",
    "        qa_dataset.append({\n",
    "            \"id\": row['id'],\n",
    "            \"image\": row['image'],\n",
    "            \"question\": brand_q,\n",
    "            \"answer\": row['brand'],\n",
    "        })\n",
    "        qa_dataset.append({\n",
    "            \"id\": row['id'],\n",
    "            \"image\": row['image'],\n",
    "            \"question\": color_q,\n",
    "            \"answer\": row['Exterior color'],\n",
    "        })\n",
    "        qa_dataset.append({\n",
    "            \"id\": row['id'],\n",
    "            \"image\": row['image'],\n",
    "            \"question\": type_q,\n",
    "            \"answer\": row['name'],\n",
    "        })\n",
    "    return qa_dataset\n",
    "\n",
    "###\n",
    "train = pipeline_create_qa_dataset(train)\n",
    "validation = pipeline_create_qa_dataset(validation)\n",
    "test = pipeline_create_qa_dataset(test)\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "validation = pd.DataFrame(validation)\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
