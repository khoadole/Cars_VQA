{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã truy cập trang web thành công.\n",
      "Đã tìm thấy: Financing - https://www.cars.com/new-cars/finance/\n",
      "Đã tìm thấy: Find a Car - https://www.cars.com/new-cars/shopping/\n",
      "Đã tìm thấy: Find a Dealer - https://www.cars.com/new-cars/dealers/buy/\n",
      "Đã tìm thấy: Listings by City - https://www.cars.com/new-cars/sitemap/city-listings/\n",
      "Đã tìm thấy: Certified Pre-Owned - https://www.cars.com/new-cars/cpo/\n",
      "Đã tìm thấy: Car Payment Calculators - https://www.cars.com/new-cars/car-loan-calculator/\n",
      "Đã tìm thấy: Car Reviews & Ratings - https://www.cars.com/new-cars/reviews/\n",
      "Đã tìm thấy: Compare Side by Side - https://www.cars.com/new-cars/research/compare/\n",
      "Đã tìm thấy: Fraud Awareness - https://www.cars.com/new-cars/fraud-awareness/\n",
      "Đã tìm thấy: Sell Your Car - https://www.cars.com/new-cars/sell/\n",
      "Lỗi khi crawl: [Errno 2] No such file or directory: 'dataset/car_brands.json'\n",
      "\n",
      "Danh sách thương hiệu xe tìm được:\n",
      "- Financing: https://www.cars.com/new-cars/finance/\n",
      "- Find a Car: https://www.cars.com/new-cars/shopping/\n",
      "- Find a Dealer: https://www.cars.com/new-cars/dealers/buy/\n",
      "- Listings by City: https://www.cars.com/new-cars/sitemap/city-listings/\n",
      "- Certified Pre-Owned: https://www.cars.com/new-cars/cpo/\n",
      "- Car Payment Calculators: https://www.cars.com/new-cars/car-loan-calculator/\n",
      "- Car Reviews & Ratings: https://www.cars.com/new-cars/reviews/\n",
      "- Compare Side by Side: https://www.cars.com/new-cars/research/compare/\n",
      "- Fraud Awareness: https://www.cars.com/new-cars/fraud-awareness/\n",
      "- Sell Your Car: https://www.cars.com/new-cars/sell/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Định nghĩa lớp CarInfo (đơn giản hóa)\n",
    "class CarInfo:\n",
    "    def __init__(self, brand: str, url: str):\n",
    "        self.brand = brand\n",
    "        self.url = url\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\"brand\": self.brand, \"url\": self.url}\n",
    "\n",
    "# Lớp cơ sở BaseScraper\n",
    "class BaseScraper(ABC):\n",
    "    def __init__(self, base_url: str):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "    \n",
    "    def get_soup(self, url: str) -> BeautifulSoup:\n",
    "        response = self.session.get(url, headers=self.headers)\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_all_car_urls(self) -> List[Dict[str, str]]:\n",
    "        pass\n",
    "\n",
    "# Lớp Website2Scraper để crawl\n",
    "class Website2Scraper(BaseScraper):\n",
    "    def save_to_json(self, filename: str, data: List[Dict]):\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    existing_data = json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    existing_data = []\n",
    "        else:\n",
    "            existing_data = []\n",
    "        \n",
    "        existing_data.extend(data)\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(existing_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def get_all_car_urls(self) -> List[Dict[str, str]]:\n",
    "        all_car_urls = []\n",
    "        try:\n",
    "            # Lấy HTML từ base_url\n",
    "            soup = self.get_soup(self.base_url)\n",
    "            print(\"Đã truy cập trang web thành công.\")\n",
    "\n",
    "            # Tìm danh sách thương hiệu xe (cập nhật bộ chọn dựa trên cấu trúc mới)\n",
    "            # Giả sử danh sách thương hiệu nằm trong thẻ ul với class \"brand-list\"\n",
    "            brand_section = soup.find(\"ul\", class_=\"sds-list\")  # Cập nhật class nếu cần\n",
    "            if not brand_section:\n",
    "                print(\"Không tìm thấy danh sách thương hiệu.\")\n",
    "                return all_car_urls\n",
    "\n",
    "            # Lấy tất cả các liên kết thương hiệu\n",
    "            brand_links = brand_section.find_all(\"a\")\n",
    "            for link in brand_links:\n",
    "                brand_name = link.text.strip()\n",
    "                brand_href = link.get(\"href\")\n",
    "                if brand_href:\n",
    "                    full_url = brand_href if brand_href.startswith(\"http\") else f\"{self.base_url.rstrip('/')}/{brand_href.lstrip('/')}\"\n",
    "                    all_car_urls.append({\"brand\": brand_name, \"url\": full_url})\n",
    "                    print(f\"Đã tìm thấy: {brand_name} - {full_url}\")\n",
    "\n",
    "            # Lưu kết quả vào file JSON\n",
    "            if all_car_urls:\n",
    "                self.save_to_json(\"dataset/car_brands.json\", all_car_urls)\n",
    "                print(\"Đã lưu danh sách thương hiệu vào 'dataset/car_brands.json'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi crawl: {e}\")\n",
    "\n",
    "        return all_car_urls\n",
    "\n",
    "# Chạy thử\n",
    "if __name__ == \"__main__\":\n",
    "    # Khởi tạo scraper với URL mới\n",
    "    scraper = Website2Scraper(\"https://www.cars.com/new-cars/\")\n",
    "    car_brands = scraper.get_all_car_urls()\n",
    "\n",
    "    # In kết quả để kiểm tra\n",
    "    if car_brands:\n",
    "        print(\"\\nDanh sách thương hiệu xe tìm được:\")\n",
    "        for item in car_brands:\n",
    "            print(f\"- {item['brand']}: {item['url']}\")\n",
    "    else:\n",
    "        print(\"Không tìm thấy thương hiệu nào.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tìm thấy: Financing - https://www.cars.com/new-cars/finance/\n",
      "Đã tìm thấy: Find a Car - https://www.cars.com/new-cars/shopping/\n",
      "Đã tìm thấy: Find a Dealer - https://www.cars.com/new-cars/dealers/buy/\n",
      "Đã tìm thấy: Listings by City - https://www.cars.com/new-cars/sitemap/city-listings/\n",
      "Đã tìm thấy: Certified Pre-Owned - https://www.cars.com/new-cars/cpo/\n",
      "Đã tìm thấy: Car Payment Calculators - https://www.cars.com/new-cars/car-loan-calculator/\n",
      "Đã tìm thấy: Car Reviews & Ratings - https://www.cars.com/new-cars/reviews/\n",
      "Đã tìm thấy: Compare Side by Side - https://www.cars.com/new-cars/research/compare/\n",
      "Đã tìm thấy: Fraud Awareness - https://www.cars.com/new-cars/fraud-awareness/\n",
      "Đã tìm thấy: Sell Your Car - https://www.cars.com/new-cars/sell/\n",
      "Đã lưu danh sách thương hiệu vào 'dataset/car_brands.json'.\n",
      "\n",
      "Danh sách thương hiệu xe tìm được:\n",
      "- Financing: https://www.cars.com/new-cars/finance/\n",
      "- Find a Car: https://www.cars.com/new-cars/shopping/\n",
      "- Find a Dealer: https://www.cars.com/new-cars/dealers/buy/\n",
      "- Listings by City: https://www.cars.com/new-cars/sitemap/city-listings/\n",
      "- Certified Pre-Owned: https://www.cars.com/new-cars/cpo/\n",
      "- Car Payment Calculators: https://www.cars.com/new-cars/car-loan-calculator/\n",
      "- Car Reviews & Ratings: https://www.cars.com/new-cars/reviews/\n",
      "- Compare Side by Side: https://www.cars.com/new-cars/research/compare/\n",
      "- Fraud Awareness: https://www.cars.com/new-cars/fraud-awareness/\n",
      "- Sell Your Car: https://www.cars.com/new-cars/sell/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "\n",
    "def create_session():\n",
    "    \"\"\"Tạo session requests với headers cố định\"\"\"\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    })\n",
    "    return session\n",
    "\n",
    "def get_soup(session, url):\n",
    "    \"\"\"Lấy BeautifulSoup từ URL\"\"\"\n",
    "    try:\n",
    "        response = session.get(url)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Lỗi khi truy cập {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_to_json(filename, data):\n",
    "    \"\"\"Lưu dữ liệu vào file JSON\"\"\"\n",
    "    # Đọc dữ liệu hiện tại (nếu có)\n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                existing_data = json.load(f)\n",
    "        else:\n",
    "            existing_data = []\n",
    "    except (json.JSONDecodeError, FileNotFoundError):\n",
    "        existing_data = []\n",
    "    \n",
    "    # Mở rộng dữ liệu\n",
    "    existing_data.extend(data)\n",
    "    \n",
    "    # Tạo thư mục nếu chưa tồn tại\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    \n",
    "    # Lưu dữ liệu\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(existing_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def get_all_car_urls(base_url):\n",
    "    \"\"\"Lấy danh sách các URL thương hiệu xe\"\"\"\n",
    "    all_car_urls = []\n",
    "    \n",
    "    # Tạo session\n",
    "    session = create_session()\n",
    "    \n",
    "    try:\n",
    "        # Lấy HTML từ base_url\n",
    "        soup = get_soup(session, base_url)\n",
    "        \n",
    "        if not soup:\n",
    "            print(\"Không thể lấy dữ liệu từ trang web.\")\n",
    "            return all_car_urls\n",
    "        \n",
    "        # Tìm danh sách thương hiệu xe\n",
    "        brand_section = soup.find(\"ul\", class_=\"sds-list\")\n",
    "        \n",
    "        if not brand_section:\n",
    "            print(\"Không tìm thấy danh sách thương hiệu.\")\n",
    "            return all_car_urls\n",
    "        \n",
    "        # Lấy tất cả các liên kết thương hiệu\n",
    "        brand_links = brand_section.find_all(\"a\")\n",
    "        \n",
    "        for link in brand_links:\n",
    "            brand_name = link.text.strip()\n",
    "            brand_href = link.get(\"href\")\n",
    "            \n",
    "            if brand_href:\n",
    "                # Xử lý URL tuyệt đối hoặc tương đối\n",
    "                full_url = brand_href if brand_href.startswith(\"http\") else f\"{base_url.rstrip('/')}/{brand_href.lstrip('/')}\"\n",
    "                \n",
    "                # Thêm vào danh sách\n",
    "                car_info = {\"brand\": brand_name, \"url\": full_url}\n",
    "                all_car_urls.append(car_info)\n",
    "                print(f\"Đã tìm thấy: {brand_name} - {full_url}\")\n",
    "        \n",
    "        # Lưu kết quả vào file JSON\n",
    "        if all_car_urls:\n",
    "            save_to_json(\"dataset/car_brands.json\", all_car_urls)\n",
    "            print(\"Đã lưu danh sách thương hiệu vào 'dataset/car_brands.json'.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi crawl: {e}\")\n",
    "    \n",
    "    return all_car_urls\n",
    "\n",
    "def main():\n",
    "    # URL để crawl\n",
    "    base_url = \"https://www.cars.com/new-cars/\"\n",
    "    \n",
    "    # Lấy danh sách các URL thương hiệu xe\n",
    "    car_brands = get_all_car_urls(base_url)\n",
    "    \n",
    "    # In kết quả\n",
    "    if car_brands:\n",
    "        print(\"\\nDanh sách thương hiệu xe tìm được:\")\n",
    "        for item in car_brands:\n",
    "            print(f\"- {item['brand']}: {item['url']}\")\n",
    "    else:\n",
    "        print(\"Không tìm thấy thương hiệu nào.\")\n",
    "\n",
    "# Chạy chính\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
